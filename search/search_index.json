{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>Combining sqlite-utils data management + Pydantic data validation for data that will (later) be deployed in a specific Datasette project: LawData.</p>"},{"location":"#stack","title":"Stack","text":"<p>In handling data that persists, we'll be using two layers of code:</p> Layer Dimension App <code>sqlite-utils</code> + <code>Pydantic</code> Database <code>sqlite</code> <p>Though <code>sqlite</code> features are frequently evolving, see json1, fts5, etc., it lacks a more robust validation mechanism. <code>Pydantic</code> would be useful to: (a) clean and validate a model's fields prior to database insertion; and (b) reuse extracted data from the database. Since the database query syntax (SQL) is different from the app syntax (python), a useful bridge is <code>sqlite-utils</code> which allows us, via this package, to use pre-defined Pydantic field attributes as a means of creating dynamic SQL statements.</p> <p>Put another way, this is an attempt to integrate the two tools so that the models declared in Pydantic can be consumed directly by sqlite-utils.</p> <p>The opinionated use of default configurations is intended for a specific project. Later on, may consider making this more general in scope.</p>"},{"location":"#connection","title":"Connection","text":"<p>Connect to a database declared by an <code>.env</code> file through a <code>DB_FILE</code> variable, e.g.</p> Bash<pre><code>DB_FILE=\"code/sqlpyd/test.db\"\n</code></pre> <p>With the .env file created, the following sqlite <code>sqlpyd.Connection</code> object gets a typed <code>Table</code>:</p> Python<pre><code>&gt;&gt;&gt; from sqlpyd import Connection\n&gt;&gt;&gt; from sqlite_utils.db import Table\n&gt;&gt;&gt; conn = Connection()  # will use .env file's DB_FILE value\n&gt;&gt;&gt; conn.db[\"test_table\"].insert({\"text\": \"hello-world\"}, pk=\"id\")  # will contain a db object\n&gt;&gt;&gt; isinstance(conn.tbl(\"test_table\"), Table)\nTrue\n</code></pre> <p>There appears to be movement to make sqlite-utils more type-friendly, see issue.</p>"},{"location":"#fields","title":"Fields","text":""},{"location":"#generic-pydantic-model","title":"Generic Pydantic Model","text":"<p>Let's assume a generic pydantic BaseModel with a non-primitive field like <code>suffix</code> and <code>gender</code>:</p> Python<pre><code># see sqlpyd/name.py\nclass Gender(str, Enum):\nmale = \"male\"\nfemale = \"female\"\nother = \"unspecified\"\nclass Suffix(str, Enum):\njr = \"Jr.\"\nsr = \"Sr.\"\nthird = \"III\"\nfourth = \"IV\"\nfifth = \"V\"\nsixth = \"VI\"\nclass IndividualBio(BaseModel):\nfirst_name: str = Field(None, max_length=50)\nlast_name: str = Field(None, max_length=50)\nsuffix: Suffix | None = Field(None, max_length=4)\nnick_name: str = Field(None, max_length=50)\ngender: Gender | None = Field(Gender.other)\nclass Config:\nuse_enum_values = True\n</code></pre> <p>With the BaseModel, we can get the types directly using:</p> Python<pre><code>&gt;&gt;&gt; IndividualBio.__annotations__\n{\n\"first_name\": str,\n\"last_name\": str,\n\"suffix\": sqlpyd.__main__.Suffix | None,  # is non-primitive / optional\n\"nick_name\": str,\n\"gender\": sqlpyd.__main__.Gender | None,  # is non-primitive  / optional\n}\n</code></pre> <p>Using the sqlite-utils convention of creating tables, this will throw an error:</p> Python<pre><code>&gt;&gt;&gt; from sqlpyd import Connection  # thin wrapper over sqlite-utils Database()\n&gt;&gt;&gt; conn = Connection(DatabasePath=\"created.db\")\n&gt;&gt;&gt; conn.db[\"test_tbl\"].create(columns=IndividualBio.__annotations__)\n...\nKeyError: sqlpyd.__main__.Suffix | None\n</code></pre>"},{"location":"#data-modelling-input-validation","title":"Data Modelling &amp; Input Validation","text":"<p>We could rewrite the needed columns and use sqlite-utils:</p> Python<pre><code>conn.db[\"test_tbl\"].create(\ncolumns={\n\"first_name\": str,\n\"last_name\": str,\n\"suffix\": str,\n\"nick_name\": str,\n\"gender\": str,\n}\n)\n# &lt;Table test_tbl (first_name, last_name, suffix, nick_name, gender)&gt;\n</code></pre> <p>But we can also modify the initial Pydantic model and co-inherit from  <code>sqlpyd.TableConfig</code>, to wit:</p> Python<pre><code>class RegularName(\nBaseModel\n):  # separated the name to add a clear pre-root validator, note addition to field attributes\nfull_name: str | None = Field(None, col=str, fts=True, index=True)\nfirst_name: str = Field(..., max_length=50, col=str, fts=True)\nlast_name: str = Field(..., max_length=50, col=str, fts=True, index=True)\nsuffix: Suffix | None = Field(None, max_length=4, col=str)\nclass Config:\nuse_enum_values = True\n@root_validator(pre=True)\ndef set_full_name(cls, values):\nif not values.get(\"full_name\"):\nfirst = values.get(\"first_name\")\nlast = values.get(\"last_name\")\nif first and last:\nvalues[\"full_name\"] = f\"{first} {last}\"\nif sfx := values.get(\"suffix\"):\nvalues[\"full_name\"] += f\", {sfx}\"\nreturn values\nclass IndividualBio(\nTableConfig\n):  # mandatory step:  inherit from TableConfig (which inherits from BaseModel)\n__tablename__ = \"person_tbl\"  # optional: may declare a tablename\n__indexes__ = [[\"first_name\", \"last_name\"]]  # optional: may declare joined indexes\nnick_name: str | None = Field(None, max_length=50, col=str, fts=True)\ngender: Gender | None = Field(Gender.other, max_length=15, col=str)\n@validator(\"gender\", pre=True)\ndef lower_cased_gender(cls, v):\nreturn Gender(v.lower()) if v else None\n</code></pre> <p>With this setup, we can use the connection to create the table. Note that the primary key <code>id</code> is auto-generated in this scenario:</p> Python<pre><code>&gt;&gt;&gt; conn = Connection(DatabasePath=\"test.db\", WAL=False)\n&gt;&gt;&gt; conn.create_table(IndividualBio)\n&lt;Table person_tbl (id, full_name, first_name, last_name, suffix, nick_name, gender)&gt;\n&gt;&gt;&gt; person2 = {  # dict\n\"first_name\": \"Jane\",\n\"last_name\": \"Doe\",\n\"suffix\": None,\n\"gender\": \"FEMALE\",  # all caps\n\"nick_name\": \"Jany\",\n}\n&gt;&gt;&gt; IndividualBio.__validators__  # note that we created a validator for 'gender'\n{'gender': [&lt;pydantic.class_validators.Validator object at 0x10c497510&gt;]}\n&gt;&gt;&gt; IndividualBio.__pre_root_validators__()  # we also have one to create a 'full_name'\n[&lt;function RegularName.set_full_name at 0x10c4b43a0&gt;]\n&gt;&gt;&gt; tbl = conn.add_record(IndividualBio, person2)  # under the hood, the dict is instantiated to a Pydantic model and the resulting `tbl` value is an sqlite-utils Table\n&gt;&gt;&gt; assert list(tbl.rows) == [\n{\n\"id\": 1,  # auto-generated\n\"full_name\": \"Jane Doe\",  # since the model contains a pre root-validator, it adds a full name\n\"first_name\": \"Jane\",\n\"last_name\": \"Doe\",\n\"suffix\": None,\n\"nick_name\": \"Jany\",\n\"gender\": \"female\",  # since the model contains a validator, it cleans the same prior to database entry\n}\n]\nTrue\n</code></pre>"},{"location":"#attributes","title":"Attributes","text":"<p><code>sqlite-utils</code> is a far more powerful solution than the limited subset of features provided here. Again, this abstraction is for the purpose of easily reusing the functionality for a specific project rather than for something more generalized.</p>"},{"location":"#columns-in-general","title":"Columns In General","text":"<p>Using <code>col</code> in the Pydantic Field signals the need to add the field to an sqlite database table:</p> Python<pre><code>conn = Connection(DatabasePath=\"test.db\", WAL=False)\nkls = IndividualBio\ntbl = conn.db[kls.__tablename__]\ncols = kls.extract_cols(kls.__fields__)  # possible fields to use\n\"\"\"\n{'first_name': str,\n 'last_name': str,\n 'suffix': str,\n 'nick_name': str,\n 'gender': str}\n\"\"\"\ntbl.create(cols)  # customize tablename and column types\n# &lt;Table individual_bio_tbl (first_name, last_name, suffix, nick_name, gender)&gt;\n</code></pre>"},{"location":"#primary-key","title":"Primary Key","text":"<p>To auto-generate, use the <code>TableConfig.config_tbl()</code> helper. It auto-creates the <code>id</code> field as an <code>int</code>-based primary key.</p> <p>Note: if an <code>id</code> is declared as a <code>str</code> in the pydantic model, the <code>str</code> declaration takes precedence over the implicit <code>int</code> default.</p> Python<pre><code>conn = Connection(DatabasePath=\"test_db.db\")\nkls = IndividualBio\ntbl = conn.db[kls.__tablename__]\ntbl_created = kls.config_tbl(tbl=tbl, cols=kls.__fields__)\n# &lt;Table individual_bio_tbl (id, first_name, last_name, suffix, nick_name, gender)&gt; # id now added\n</code></pre> <p>This results in the following sql schema:</p> SQL<pre><code>CREATE TABLE [individual_bio_tbl] (\n[id] INTEGER PRIMARY KEY, -- added as integer since no field specified\n[first_name] TEXT NOT NULL, -- required via Pydantic's ...\n[last_name] TEXT NOT NULL, -- required via Pydantic's ...\n[suffix] TEXT,\n[nick_name] TEXT,\n[gender] TEXT\n)\n</code></pre>"},{"location":"#full-text-search-fts-fields","title":"Full-Text Search (fts) Fields","text":"<p>Since we indicated, in the above declaration of <code>Fields</code>, that some columns are to be used for <code>fts</code>, we enable sqlite-utils to auto-generate the tables required. This makes possible the prescribed approach of querying fts tables:</p> Python<pre><code># Using the same variable for `tbl` described above, can yield a query string, viz.\nprint(tbl.search_sql(columns=[\"first_name\", \"last_name\"]))\n</code></pre> <p>produces:</p> SQL<pre><code>with original as (\nselect\nrowid,\n[first_name],\n[last_name]\nfrom [individual_bio_tbl]\n)\nselect\n[original].[first_name],\n[original].[last_name]\nfrom\n[original]\njoin [individual_bio_tbl_fts] on [original].rowid = [individual_bio_tbl_fts].rowid\nwhere\n[individual_bio_tbl_fts] match :query\norder by\n[individual_bio_tbl_fts].rank\n</code></pre>"},{"location":"#foreign-keys","title":"Foreign Keys","text":"<p>To add foreign keys, can use the <code>fk</code> attribute on a ModelField, assigning the same to a 2-tuple, e.g.:</p> Python<pre><code>class GroupedIndividuals(TableConfig):\n__tablename__ = \"grouping_tbl\"\n__indexes__ = [[\"member_id\", \"name\"]]\nname: str = Field(..., max_length=50, col=str)\nmember_id: int = Field(\n..., col=int, fk=(IndividualBio.__tablename__, \"id\"), index=True\n)\n</code></pre> <p>Parts of <code>fk</code> tuple:</p> <ul> <li>The first part of the <code>fk</code> tuple is the referenced table name X.</li> <li>The second part of the <code>fk</code> tuple is the id of X.</li> </ul> <p>So in the above example, <code>member_id</code>, the Pydantic field, is constrained to the \"id\" column of the table \"individual_bio_tbl\"</p>"},{"location":"#indexes","title":"Indexes","text":"<p>Note that we can add an index to each field as well with a boolean <code>True</code> to a ModelField attribute <code>index</code>. In case we want to use a combination of columns for the index, can include this when subclassing <code>TableConfig</code>:</p> Python<pre><code>class GroupedIndividuals(TableConfig):\n__tablename__ = \"grouping_tbl\"\n__indexes__ = [[\"member_id\", \"name\"]]  # follow sqlite-utils convention\n</code></pre> <p>When combined, the sql generated amounts to the following:</p> SQL<pre><code>CREATE TABLE [grouping_tbl] (\n[id] INTEGER PRIMARY KEY,\n[name] TEXT NOT NULL,\n[member_id] INTEGER NOT NULL REFERENCES [individual_bio_tbl]([id])\n);\nCREATE UNIQUE INDEX [idx_grouping_tbl_member_id]\nON [grouping_tbl] ([member_id]);\nCREATE UNIQUE INDEX [idx_grouping_tbl_name_member_id]\nON [grouping_tbl] ([name], [member_id]);\n</code></pre>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#connection","title":"Connection","text":"<p>         Bases: <code>BaseSettings</code></p> <p>Thin wrapper over <code>sqlite-utils.Database</code> (which itself wraps around <code>sqlite3.connect</code>) with some convenience methods.</p> Source code in <code>sqlpyd/conn.py</code> Python<pre><code>class Connection(BaseSettings):\n\"\"\"\n    Thin wrapper over `sqlite-utils.Database`\n    (which itself wraps around `sqlite3.connect`)\n    with some convenience methods.\n    \"\"\"\nDatabasePath: str | None = Field(\nNone,\nenv=\"DB_FILE\",\ndescription=\"Intended / existing path to db from present working dir.\",\n)\nWAL: bool | None = Field(False, title=\"Write Ahead Logging.\")\nclass Config:\nenv_file = \".env\"\nenv_file_encoding = \"utf-8\"\n@property\ndef path_to_db(self) -&gt; Path | None:\nif self.DatabasePath:\nreturn Path().cwd().joinpath(self.DatabasePath)\nreturn None\n@property\ndef db(self) -&gt; Database:\nif self.path_to_db:\nobj = Database(self.path_to_db, use_counts_table=True)\nif self.WAL:\nobj.enable_wal()\nreturn obj\nreturn Database(filename_or_conn=None, memory=True)\n@property\n@contextmanager\ndef session(self) -&gt; Iterator[sqlite3.Cursor]:\nconn = self.db.conn\ncur = conn.cursor()\nyield cur\nconn.commit()\nconn.close()\ndef tbl(self, table_name: str) -&gt; Table:\n\"\"\"Should use string represented by kls.__tablename__\n        to retrieve the table instance.\n        Args:\n            table_name (str): The name of the sqlite table.\n        Raises:\n            Exception: No table found.\n        Returns:\n            Table: The sqlite-utils.db Table instance.\n        \"\"\"\ntbl = self.db.table(table_name)\nif isinstance(tbl, Table):\nreturn tbl\nraise Exception(f\"No {tbl=}\")\ndef table(self, kls) -&gt; Table:\n\"\"\"Using the TableConfig kls to retrieve the table instance.\"\"\"\nif not issubclass(kls, TableConfig):\nraise NotImplementedError(f\"{kls} must be a TableConfig.\")\ntbl_obj = self.db.table(kls.__tablename__)\nif tbl_obj.exists() and isinstance(tbl_obj, Table):\nreturn tbl_obj\nraise Exception(f\"No {tbl_obj=}\")\ndef create_table(self, kls: Any) -&gt; Table:\n\"\"\"Create a `TableConfig` table, if it doesn't exist yet,\n        having attributes declared in the `kls`.\n        Args:\n            kls (Any): Assumes that `kls` is a subclass of `TableConfig`.\n        Raises:\n            NotImplementedError: The `kls` is invalid.\n        Returns:\n            Table: The sqlite-utils.db Table instance.\n        \"\"\"\nif not issubclass(kls, TableConfig):\nraise NotImplementedError(f\"{kls} must be a TableConfig.\")\nreturn kls.config_tbl(self.tbl(kls.__tablename__))\ndef add_record(self, kls: Any, item: dict) -&gt; Table:\n\"\"\"With a TableConfig `kls` (that is representing or should represent\n        an sqlite table), add a record to the same which will be cleaned via\n        Pydantic prior to being inserted by sqlite-utils.\n        Args:\n            kls (Any): preconfigured `TableConfig` entity\n            item (dict): Raw data representing fields that match the `kls`\n        Returns:\n            Table: The sqlite-utils.db Table instance.\n        \"\"\"\nreturn self.create_table(kls).insert(\nkls(**item).dict(exclude_none=True)\n)\ndef add_records(\nself, kls, items: Iterable[dict] | Iterator[dict]\n) -&gt; Table:\n\"\"\"With a TableConfig `kls` (that is representing or should represent\n        an sqlite table), add multiple records to the same which will be\n        cleaned via Pydantic prior to being inserted by sqlite-utils.\n        Args:\n            kls (Any): preconfigured `TableConfig` entity\n            items (Iterable[dict] | Iterator[dict]): Each item matches `kls`\n        Returns:\n            Table: _description_\n        \"\"\"\nreturn self.create_table(kls).insert_all(\nkls(**item).dict(exclude_none=True) for item in items\n)\ndef add_cleaned_records(\nself, kls, items: Iterable[Any] | Iterator[Any]\n) -&gt; Table:\n\"\"\"Compare this with `add_records()`. If records have already been\n        previously validated, no need for a deserialization step.\n        Args:\n            kls (Any): preconfigured `TableConfig` entity\n            items (Iterable[dict] | Iterator[dict]): Each item matches `kls`\n        Returns:\n            Table: _description_\n        \"\"\"\nreturn self.create_table(kls).insert_all(\ni.dict(exclude_none=True) for i in items\n)\n</code></pre>"},{"location":"reference/#sqlpyd.conn.Connection-functions","title":"Functions","text":""},{"location":"reference/#sqlpyd.conn.Connection.add_cleaned_records","title":"<code>add_cleaned_records(kls, items)</code>","text":"<p>Compare this with <code>add_records()</code>. If records have already been previously validated, no need for a deserialization step.</p> <p>Parameters:</p> Name Type Description Default <code>kls</code> <code>Any</code> <p>preconfigured <code>TableConfig</code> entity</p> required <code>items</code> <code>Iterable[dict] | Iterator[dict]</code> <p>Each item matches <code>kls</code></p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>description</p> Source code in <code>sqlpyd/conn.py</code> Python<pre><code>def add_cleaned_records(\nself, kls, items: Iterable[Any] | Iterator[Any]\n) -&gt; Table:\n\"\"\"Compare this with `add_records()`. If records have already been\n    previously validated, no need for a deserialization step.\n    Args:\n        kls (Any): preconfigured `TableConfig` entity\n        items (Iterable[dict] | Iterator[dict]): Each item matches `kls`\n    Returns:\n        Table: _description_\n    \"\"\"\nreturn self.create_table(kls).insert_all(\ni.dict(exclude_none=True) for i in items\n)\n</code></pre>"},{"location":"reference/#sqlpyd.conn.Connection.add_record","title":"<code>add_record(kls, item)</code>","text":"<p>With a TableConfig <code>kls</code> (that is representing or should represent an sqlite table), add a record to the same which will be cleaned via Pydantic prior to being inserted by sqlite-utils.</p> <p>Parameters:</p> Name Type Description Default <code>kls</code> <code>Any</code> <p>preconfigured <code>TableConfig</code> entity</p> required <code>item</code> <code>dict</code> <p>Raw data representing fields that match the <code>kls</code></p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>The sqlite-utils.db Table instance.</p> Source code in <code>sqlpyd/conn.py</code> Python<pre><code>def add_record(self, kls: Any, item: dict) -&gt; Table:\n\"\"\"With a TableConfig `kls` (that is representing or should represent\n    an sqlite table), add a record to the same which will be cleaned via\n    Pydantic prior to being inserted by sqlite-utils.\n    Args:\n        kls (Any): preconfigured `TableConfig` entity\n        item (dict): Raw data representing fields that match the `kls`\n    Returns:\n        Table: The sqlite-utils.db Table instance.\n    \"\"\"\nreturn self.create_table(kls).insert(\nkls(**item).dict(exclude_none=True)\n)\n</code></pre>"},{"location":"reference/#sqlpyd.conn.Connection.add_records","title":"<code>add_records(kls, items)</code>","text":"<p>With a TableConfig <code>kls</code> (that is representing or should represent an sqlite table), add multiple records to the same which will be cleaned via Pydantic prior to being inserted by sqlite-utils.</p> <p>Parameters:</p> Name Type Description Default <code>kls</code> <code>Any</code> <p>preconfigured <code>TableConfig</code> entity</p> required <code>items</code> <code>Iterable[dict] | Iterator[dict]</code> <p>Each item matches <code>kls</code></p> required <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>description</p> Source code in <code>sqlpyd/conn.py</code> Python<pre><code>def add_records(\nself, kls, items: Iterable[dict] | Iterator[dict]\n) -&gt; Table:\n\"\"\"With a TableConfig `kls` (that is representing or should represent\n    an sqlite table), add multiple records to the same which will be\n    cleaned via Pydantic prior to being inserted by sqlite-utils.\n    Args:\n        kls (Any): preconfigured `TableConfig` entity\n        items (Iterable[dict] | Iterator[dict]): Each item matches `kls`\n    Returns:\n        Table: _description_\n    \"\"\"\nreturn self.create_table(kls).insert_all(\nkls(**item).dict(exclude_none=True) for item in items\n)\n</code></pre>"},{"location":"reference/#sqlpyd.conn.Connection.create_table","title":"<code>create_table(kls)</code>","text":"<p>Create a <code>TableConfig</code> table, if it doesn't exist yet, having attributes declared in the <code>kls</code>.</p> <p>Parameters:</p> Name Type Description Default <code>kls</code> <code>Any</code> <p>Assumes that <code>kls</code> is a subclass of <code>TableConfig</code>.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>The <code>kls</code> is invalid.</p> <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>The sqlite-utils.db Table instance.</p> Source code in <code>sqlpyd/conn.py</code> Python<pre><code>def create_table(self, kls: Any) -&gt; Table:\n\"\"\"Create a `TableConfig` table, if it doesn't exist yet,\n    having attributes declared in the `kls`.\n    Args:\n        kls (Any): Assumes that `kls` is a subclass of `TableConfig`.\n    Raises:\n        NotImplementedError: The `kls` is invalid.\n    Returns:\n        Table: The sqlite-utils.db Table instance.\n    \"\"\"\nif not issubclass(kls, TableConfig):\nraise NotImplementedError(f\"{kls} must be a TableConfig.\")\nreturn kls.config_tbl(self.tbl(kls.__tablename__))\n</code></pre>"},{"location":"reference/#sqlpyd.conn.Connection.table","title":"<code>table(kls)</code>","text":"<p>Using the TableConfig kls to retrieve the table instance.</p> Source code in <code>sqlpyd/conn.py</code> Python<pre><code>def table(self, kls) -&gt; Table:\n\"\"\"Using the TableConfig kls to retrieve the table instance.\"\"\"\nif not issubclass(kls, TableConfig):\nraise NotImplementedError(f\"{kls} must be a TableConfig.\")\ntbl_obj = self.db.table(kls.__tablename__)\nif tbl_obj.exists() and isinstance(tbl_obj, Table):\nreturn tbl_obj\nraise Exception(f\"No {tbl_obj=}\")\n</code></pre>"},{"location":"reference/#sqlpyd.conn.Connection.tbl","title":"<code>tbl(table_name)</code>","text":"<p>Should use string represented by kls.tablename to retrieve the table instance.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the sqlite table.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>No table found.</p> <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>The sqlite-utils.db Table instance.</p> Source code in <code>sqlpyd/conn.py</code> Python<pre><code>def tbl(self, table_name: str) -&gt; Table:\n\"\"\"Should use string represented by kls.__tablename__\n    to retrieve the table instance.\n    Args:\n        table_name (str): The name of the sqlite table.\n    Raises:\n        Exception: No table found.\n    Returns:\n        Table: The sqlite-utils.db Table instance.\n    \"\"\"\ntbl = self.db.table(table_name)\nif isinstance(tbl, Table):\nreturn tbl\nraise Exception(f\"No {tbl=}\")\n</code></pre>"},{"location":"reference/#tableconfig","title":"TableConfig","text":"<p>         Bases: <code>BaseModel</code></p> <p>Adds custom <code>pydantic.Field</code> attributes:</p> Attribute Value Function <code>col</code> <code>str</code>, <code>int</code>, etc. Accepts a primitive Python type understandable by <code>sqlite-utils</code> <code>fk</code> tuple[str, str] First value: the name of the table in sqlite and; second value: name of column representing the foreign key in said table <code>fts</code> <code>bool</code> If True, a full-text-search counterpart table is created including said column <code>index</code> <code>bool</code> If True, the column is created with an sqlite index` <code>required</code> <code>bool</code> If True, the column is deemed essential to instantiation <p>This enables the construction of an <code>sqlite-utils</code>-designed table.</p> <p>Note that <code>__indexes__</code> as a <code>ClassVar</code> refers to a list of Iterables that can be used as indexes to the table,based on the sqlite-utils convention. Defaults to None.</p> Source code in <code>sqlpyd/tableconfig.py</code> Python<pre><code>class TableConfig(BaseModel):\n\"\"\"Adds custom `pydantic.Field` attributes:\n    Attribute | Value | Function\n    :--:|:--:|:--:\n    `col` | `str`, `int`, etc. | Accepts a primitive Python type understandable by `sqlite-utils`\n    `fk` | tuple[str, str] | First value: the name of the table in sqlite and; second value: name of column representing the foreign key in said table\n    `fts` | `bool` | If True, a full-text-search counterpart table is created including said column\n    `index` | `bool` | If True, the column is created with an sqlite index`\n    `required` | `bool` | If True, the column is deemed essential to instantiation\n    This enables the construction of an `sqlite-utils`-designed table.\n    Note that `__indexes__` as a `ClassVar` refers to a list of Iterables that can be used as\n    indexes to the table,based on the sqlite-utils convention.\n    Defaults to None.\n    \"\"\"  # noqa: E501\n__prefix__: ClassVar[str] = \"db\"\n__tablename__: ClassVar[str]\n__indexes__: ClassVar[list[Iterable[str | DescIndex]] | None] = None\n@classmethod\ndef __init_subclass__(cls):\nif not hasattr(cls, \"__tablename__\"):\nmsg = \"Must explicitly declare a __tablename__ for TableConfig\"\nraise NotImplementedError(f\"{msg} {cls=}.\")\ncls.__tablename__ = \"_\".join(\n[cls.__prefix__, \"tbl\", cls.__tablename__]\n)\n@classmethod\ndef config_tbl(cls, tbl: Table) -&gt; Table:\n\"\"\"Using pydantic fields, generate an sqlite db table via\n        `sqlite-utils` conventions.\n        Each `pydantic.BaseModel` will have a __fields__ attribute,\n        which is a dictionary of `ModelField` values.\n        Each of these fields assigned a `col` attribute\n        will be extracted from the ModelField.\n        The extract will enable further processing on the field such\n        as introspecting the `fk`, `fts`, and `index` attributes.\n        For more complex indexes, the `idxs` attribute can be supplied\n        following the `sqlite-utils` convention.\n        Returns:\n            Table: An sqlite-utils Table object.\n        \"\"\"\nif tbl.exists():\nreturn tbl\ncols = cls.__fields__\ncreated_tbl = tbl.create(\ncolumns=cls.extract_cols(cols),\npk=\"id\",\nnot_null=cls._not_nulls(cols),\ncolumn_order=[\"id\"],  # make id the first\nforeign_keys=cls._fks(cols),\nif_not_exists=True,\n)\nsingle_indexes = cls._indexes(cols)\nif single_indexes:\nfor idx1 in single_indexes:\ntbl.create_index(columns=idx1, if_not_exists=True)\nif cls.__indexes__:\nfor idx2 in cls.__indexes__:\nif not isinstance(idx2, Iterable):\nmsg = f\"{idx2=} must follow sqlite-utils convention.\"\nraise Exception(msg)\nif len(list(idx2)) == 1:\nmsg = \"If single column index, use index= attribute.\"\nraise Exception(msg)\ntbl.create_index(columns=idx2, if_not_exists=True)\nif fts_cols := cls._fts(cols):\ncreated_tbl.enable_fts(\ncolumns=fts_cols,\ncreate_triggers=True,\ntokenize=\"porter\",\n)\nreturn created_tbl\n@classmethod\ndef extract_model_fields(\ncls, fields_data: dict[str, ModelField]\n) -&gt; Iterator[tuple[str, ModelField]]:\n\"\"\"Loop through the ModelField to extract included 2-tuples.\n        The first part of the tuple is the name of the field,\n        the second part is the ModelField.\n        Args:\n            fields_data (dict[str, ModelField]): _description_\n        Yields:\n            Iterator[tuple[str, ModelField]]: _description_\n        \"\"\"\n_pydantic_fields = [{k: v} for k, v in fields_data.items()]\nfor field in _pydantic_fields:\nfor k, v in field.items():\nif not v.field_info.exclude:  # implies inclusion\nyield (k.lower(), v)  # all keys are lower-cased\n@classmethod\ndef extract_cols(\ncls, fields_data: dict[str, ModelField]\n) -&gt; dict[str, Any]:\n\"\"\"If a `col` attribute is declared in the ModelField,\n        e.g. `name: str = Field(col=str)`, extract it.\n        Note this makes the the `id` field an `int` type by default.\n        But if an `id` field exists in the parent model and this is\n        set to a different type, e.g. `str`, this overrides the default `id`\n        previously set as an `int`.\n        Args:\n            fields_data (dict[str, ModelField]): Pydantic field\n        Returns:\n            dict[str, Any]: A mapping to be used later sqlite-utils\n        \"\"\"\ncols: dict[str, Any] = {}\ncols[\"id\"]: int  # type: ignore\nfor k, v in cls.extract_model_fields(fields_data):\nif sqlite_type := v.field_info.extra.get(\"col\"):\ncols[k] = sqlite_type\nreturn cols\n@classmethod\ndef _fts(cls, fields_data: dict[str, ModelField]) -&gt; list[str]:\n\"\"\"If `fts` attribute in ModelField is set, extract.\"\"\"\ncols: list[str] = []\nfor k, v in cls.extract_model_fields(fields_data):\nif v.field_info.extra.get(\"fts\", False):\ncols.append(k)\nreturn cols\n@classmethod\ndef _fks(\ncls, fields_data: dict[str, ModelField]\n) -&gt; list[tuple[str, str, str]] | None:\n\"\"\"If `fk` attribute in ModelField is set, extract.\"\"\"\nfk_tuples: list[tuple[str, str, str]] = []\nfor k, v in cls.extract_model_fields(fields_data):\nif fk := v.field_info.extra.get(\"fk\"):\nif isinstance(fk, tuple):\nfk_setup = (k, fk[0], fk[1])\nfk_tuples.append(fk_setup)\nreturn fk_tuples or None\n@classmethod\ndef _indexes(\ncls, fields_data: dict[str, ModelField]\n) -&gt; list[list[str]] | None:\n\"\"\"If `index` attribute in ModelField is set, extract.\"\"\"\ncols: list[list[str]] = []\nfor k, v in cls.extract_model_fields(fields_data):\nif idx := v.field_info.extra.get(\"index\"):\nif isinstance(idx, bool) and idx is True:\ncols.append([k])\nreturn cols or None\n@classmethod\ndef _not_nulls(cls, fields_data: dict[str, ModelField]) -&gt; set[str]:\n\"\"\"If `required` in the ModelField is `True`\n        and the field has not been `excluded`, extract.\n        \"\"\"\ncols: set[str] = set()\nfor k, v in cls.extract_model_fields(fields_data):\nif v.required:  # both values (required, exclude) are boolean\ncols.add(k)\nreturn cols\n</code></pre>"},{"location":"reference/#sqlpyd.tableconfig.TableConfig-functions","title":"Functions","text":""},{"location":"reference/#sqlpyd.tableconfig.TableConfig.config_tbl","title":"<code>config_tbl(tbl)</code>  <code>classmethod</code>","text":"<p>Using pydantic fields, generate an sqlite db table via <code>sqlite-utils</code> conventions.</p> <p>Each <code>pydantic.BaseModel</code> will have a fields attribute, which is a dictionary of <code>ModelField</code> values.</p> <p>Each of these fields assigned a <code>col</code> attribute will be extracted from the ModelField.</p> <p>The extract will enable further processing on the field such as introspecting the <code>fk</code>, <code>fts</code>, and <code>index</code> attributes.</p> <p>For more complex indexes, the <code>idxs</code> attribute can be supplied following the <code>sqlite-utils</code> convention.</p> <p>Returns:</p> Name Type Description <code>Table</code> <code>Table</code> <p>An sqlite-utils Table object.</p> Source code in <code>sqlpyd/tableconfig.py</code> Python<pre><code>@classmethod\ndef config_tbl(cls, tbl: Table) -&gt; Table:\n\"\"\"Using pydantic fields, generate an sqlite db table via\n    `sqlite-utils` conventions.\n    Each `pydantic.BaseModel` will have a __fields__ attribute,\n    which is a dictionary of `ModelField` values.\n    Each of these fields assigned a `col` attribute\n    will be extracted from the ModelField.\n    The extract will enable further processing on the field such\n    as introspecting the `fk`, `fts`, and `index` attributes.\n    For more complex indexes, the `idxs` attribute can be supplied\n    following the `sqlite-utils` convention.\n    Returns:\n        Table: An sqlite-utils Table object.\n    \"\"\"\nif tbl.exists():\nreturn tbl\ncols = cls.__fields__\ncreated_tbl = tbl.create(\ncolumns=cls.extract_cols(cols),\npk=\"id\",\nnot_null=cls._not_nulls(cols),\ncolumn_order=[\"id\"],  # make id the first\nforeign_keys=cls._fks(cols),\nif_not_exists=True,\n)\nsingle_indexes = cls._indexes(cols)\nif single_indexes:\nfor idx1 in single_indexes:\ntbl.create_index(columns=idx1, if_not_exists=True)\nif cls.__indexes__:\nfor idx2 in cls.__indexes__:\nif not isinstance(idx2, Iterable):\nmsg = f\"{idx2=} must follow sqlite-utils convention.\"\nraise Exception(msg)\nif len(list(idx2)) == 1:\nmsg = \"If single column index, use index= attribute.\"\nraise Exception(msg)\ntbl.create_index(columns=idx2, if_not_exists=True)\nif fts_cols := cls._fts(cols):\ncreated_tbl.enable_fts(\ncolumns=fts_cols,\ncreate_triggers=True,\ntokenize=\"porter\",\n)\nreturn created_tbl\n</code></pre>"},{"location":"reference/#sqlpyd.tableconfig.TableConfig.extract_cols","title":"<code>extract_cols(fields_data)</code>  <code>classmethod</code>","text":"<p>If a <code>col</code> attribute is declared in the ModelField, e.g. <code>name: str = Field(col=str)</code>, extract it.</p> <p>Note this makes the the <code>id</code> field an <code>int</code> type by default. But if an <code>id</code> field exists in the parent model and this is set to a different type, e.g. <code>str</code>, this overrides the default <code>id</code> previously set as an <code>int</code>.</p> <p>Parameters:</p> Name Type Description Default <code>fields_data</code> <code>dict[str, ModelField]</code> <p>Pydantic field</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A mapping to be used later sqlite-utils</p> Source code in <code>sqlpyd/tableconfig.py</code> Python<pre><code>@classmethod\ndef extract_cols(\ncls, fields_data: dict[str, ModelField]\n) -&gt; dict[str, Any]:\n\"\"\"If a `col` attribute is declared in the ModelField,\n    e.g. `name: str = Field(col=str)`, extract it.\n    Note this makes the the `id` field an `int` type by default.\n    But if an `id` field exists in the parent model and this is\n    set to a different type, e.g. `str`, this overrides the default `id`\n    previously set as an `int`.\n    Args:\n        fields_data (dict[str, ModelField]): Pydantic field\n    Returns:\n        dict[str, Any]: A mapping to be used later sqlite-utils\n    \"\"\"\ncols: dict[str, Any] = {}\ncols[\"id\"]: int  # type: ignore\nfor k, v in cls.extract_model_fields(fields_data):\nif sqlite_type := v.field_info.extra.get(\"col\"):\ncols[k] = sqlite_type\nreturn cols\n</code></pre>"},{"location":"reference/#sqlpyd.tableconfig.TableConfig.extract_model_fields","title":"<code>extract_model_fields(fields_data)</code>  <code>classmethod</code>","text":"<p>Loop through the ModelField to extract included 2-tuples. The first part of the tuple is the name of the field, the second part is the ModelField.</p> <p>Parameters:</p> Name Type Description Default <code>fields_data</code> <code>dict[str, ModelField]</code> <p>description</p> required <p>Yields:</p> Type Description <code>Iterator[tuple[str, ModelField]]</code> <p>Iterator[tuple[str, ModelField]]: description</p> Source code in <code>sqlpyd/tableconfig.py</code> Python<pre><code>@classmethod\ndef extract_model_fields(\ncls, fields_data: dict[str, ModelField]\n) -&gt; Iterator[tuple[str, ModelField]]:\n\"\"\"Loop through the ModelField to extract included 2-tuples.\n    The first part of the tuple is the name of the field,\n    the second part is the ModelField.\n    Args:\n        fields_data (dict[str, ModelField]): _description_\n    Yields:\n        Iterator[tuple[str, ModelField]]: _description_\n    \"\"\"\n_pydantic_fields = [{k: v} for k, v in fields_data.items()]\nfor field in _pydantic_fields:\nfor k, v in field.items():\nif not v.field_info.exclude:  # implies inclusion\nyield (k.lower(), v)  # all keys are lower-cased\n</code></pre>"}]}